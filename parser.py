import csv
import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.common.keys import Keys
from bs4 import BeautifulSoup

# === –ù–ê–°–¢–†–û–ô–ö–ò ===
START_URLS = [
    'https://thermex.ru/search/',
]
LOAD_MORE_CLASSES = [
    'ButtonLoadMore_show-more-button__FXKXn',
    'load-more',  # –î–æ–±–∞–≤—å —Å—é–¥–∞ –∫–ª–∞—Å—Å—ã —Å –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤
]
INPUT_FILE = "art.txt"
OUTPUT_CSV = 'dataset_output.csv'
MAX_QUERIES = 1000

# === CSV: –°–û–ó–î–ê–ù–ò–ï –ò –ó–ê–ì–û–õ–û–í–ö–û–í ===
def init_csv():
    with open(OUTPUT_CSV, mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        writer.writerow(['Site', 'Name', 'Kitchen', 'Time', 'Rate', 'Price', 'Metro'])

# === –û–ë–†–ê–ë–û–¢–ß–ò–ö "–ó–ê–ì–†–£–ó–ò–¢–¨ –ï–©–Å" ===
def load_all_content_by_classes(driver, class_list, max_clicks=50, wait_time=2):
    for class_name in class_list:
        print(f"[INFO] –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–Ω–æ–ø–∫–∏ —Å –∫–ª–∞—Å—Å–æ–º: {class_name}")
        for i in range(max_clicks):
            try:
                button = driver.find_element(By.CLASS_NAME, class_name)
                if button.is_displayed() and button.is_enabled():
                    driver.execute_script("arguments[0].scrollIntoView();", button)
                    button.click()
                    print(f"[INFO] üîÅ –ö–ª–∏–∫ –ø–æ –∫–Ω–æ–ø–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏ ({i + 1}) ‚Äî {class_name}")
                    time.sleep(wait_time)
                else:
                    print("[INFO] –ö–Ω–æ–ø–∫–∞ –Ω–∞–π–¥–µ–Ω–∞, –Ω–æ –Ω–µ–∞–∫—Ç–∏–≤–Ω–∞.")
                    break
            except NoSuchElementException:
                print(f"[INFO] –ö–Ω–æ–ø–∫–∞ '{class_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π.")
                break
            except ElementClickInterceptedException:
                print("[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å. –ü–∞—É–∑–∞.")
                time.sleep(wait_time)
        time.sleep(1)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏

# === –ü–†–û–ß–ï–ï ===
def close_popups(driver):
    try:
        popup = driver.find_element(By.CLASS_NAME, 'widget--close')
        popup.click()
        print("[INFO] Popup –∑–∞–∫—Ä—ã—Ç.")
    except NoSuchElementException:
        pass
    except ElementClickInterceptedException:
        print("[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –∫–ª–∏–∫–Ω—É—Ç—å –ø–æ popup.")

def perform_search(driver, query):
    try:
        search_box = driver.find_element(By.CLASS_NAME, "v-search-global-input")
        search_box.clear()
        search_box.send_keys(query)
        search_box.send_keys(Keys.RETURN)
        print(f"[INFO] –ü–æ–∏—Å–∫: {query}")
    except Exception as e:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –≤–≤–æ–¥–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")

def scroll_down(driver, delay=2):
    last_height = driver.execute_script("return document.body.scrollHeight")
    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(delay)
    new_height = driver.execute_script("return document.body.scrollHeight")
    return new_height != last_height

def extract_data(html_code, site_label):
    soup = BeautifulSoup(html_code, 'html.parser')
    items = soup.find_all('div', class_='CardTwoBlock_card__GFR2L Template_card__ZnZUD Listing_card__hNL_B')

    data = []
    for block in items:
        soup_block = BeautifulSoup(str(block), 'html.parser')

        name = soup_block.find('span', class_='Text_text__e9ILn Template_title__3vIhm')
        kitchen = soup_block.find('span', class_='Text_text__e9ILn TypeAndPrice_type-url__5phPv')
        time_block = soup_block.find('p', class_='Text_text__e9ILn ScheduleAndPrice_schedule__Rv03e')
        rate = soup_block.find('span', class_='Rating_rating__NLDVH')
        metro = soup_block.find('div', class_='Place_metro__sSZ56')

        active_prices = soup_block.find_all('span', {'data-active': 'true'})
        count = len(active_prices)
        if count == 1:
            price = '700'
        elif count == 2:
            price = '700 - 1700'
        elif count == 3:
            price = '1700 - 3000'
        elif count == 4:
            price = '3000'
        else:
            price = ''

        metro_text = "; ".join([item.get_text(strip=True) for item in metro.find_all('span')]) if metro else None

        row = [
            site_label,
            name.get_text(strip=True) if name else None,
            kitchen.get_text(strip=True) if kitchen else None,
            time_block.get_text(strip=True) if time_block else None,
            rate.get_text(strip=True) if rate else None,
            price,
            metro_text
        ]
        data.append(row)
    return data

def log_to_file(filename, message):
    with open(filename, 'a', encoding='utf-8') as f:
        f.write(message + '\n')

# === –û–ë–†–ê–ë–û–¢–ö–ê –û–î–ù–û–ì–û –°–ê–ô–¢–ê ===
def process_site(site_url, queries, max_queries):
    print(f"\n=== –ü–ê–†–°–ò–ú –°–ê–ô–¢: {site_url} ===\n")
    options = Options()
    # options.add_argument("--headless")
    driver = webdriver.Chrome(options=options)
    driver.maximize_window()
    driver.get(site_url)

    for idx, query in enumerate(queries):
        if idx >= max_queries:
            break
        try:
            close_popups(driver)
            perform_search(driver, query)
            time.sleep(3)

            load_all_content_by_classes(driver, LOAD_MORE_CLASSES)

            html_code = driver.page_source
            results = extract_data(html_code, site_url)

            with open(OUTPUT_CSV, mode='a', newline='', encoding='utf-8') as file:
                writer = csv.writer(file)
                writer.writerows(results)

            log_to_file("log_success.txt", f"[{site_url}] ‚úÖ {idx+1}/{max_queries} ‚Äî {query} ‚Äî {len(results)} –∑–∞–ø–∏—Å–µ–π")
            print(f"[SUCCESS] {query} ‚Üí {len(results)} –∑–∞–ø–∏—Å–µ–π")
        except Exception as e:
            log_to_file("log_errors.txt", f"[{site_url}] ‚ùå {idx+1}/{max_queries} ‚Äî {query} ‚Äî {e}")
            print(f"[ERROR] {query}: {e}")
            continue

    driver.quit()

# === –ó–ê–ü–£–°–ö ===
if __name__ == "__main__":
    init_csv()
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        queries = [line.strip() for line in f.readlines()]

    for site in START_URLS:
        process_site(site, queries, MAX_QUERIES)

    print("\n[INFO] ‚úÖ –í—Å–µ —Å–∞–π—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã.")
